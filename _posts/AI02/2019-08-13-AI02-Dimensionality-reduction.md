---
layout : post
title : AI02, Dimensionality reduction
categories: [AI02]
comments : true
tags : [AI02]
---
[Back to the previous page](https://userdyk-github.github.io/Study.html)ï½œ[Meachine learning](https://userdyk-github.github.io/ai02/AI02-Contents.html)<br>
List of posts to read before reading this article
- <a href='https://userdyk-github.github.io/'>post1</a>
- <a href='https://userdyk-github.github.io/'>post2</a>
- <a href='https://userdyk-github.github.io/'>post3</a>

---

## Contents
{:.no_toc}

* ToC
{:toc}

<hr class="division1">

## **Principal Component Analysis**

### ***When Will PCA Be Useful in Data Reduction?***

### ***How Do You Know How Much Variance Is Retained by the Selected Principal Components?***
    
    
<hr class="division2">

## **Singular Value Decomposition**

<hr class="division2">

## **Non-negative matrix factorization (NMF)**

<hr class="division2">


## **Kernel PCA**

<hr class="division2">


## **Graph-based kernel PCA**

<hr class="division2">



## **Linear discriminant analysis (LDA)**

<hr class="division2">


## **Generalized discriminant analysis (GDA)**

<hr class="division2">


## **Autoencoder**


<hr class="division1">

List of posts followed by this article
- [post1](https://userdyk-github.github.io/)
- <a href='https://userdyk-github.github.io/'>post2</a>
- <a href='https://userdyk-github.github.io/'>post3</a>

---

Reference
- [post1](https://userdyk-github.github.io/)
- <a href='https://ratsgo.github.io/machine%20learning/2017/04/24/PCA/' target="_blank">PCA</a>
- <a href='https://userdyk-github.github.io/'>post3</a>

---

<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
