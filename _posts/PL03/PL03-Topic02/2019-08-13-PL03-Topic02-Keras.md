---
layout : post
title : PL03-Topic02, Keras
categories: [PL03-Topic02]
comments : true
tags : [PL03-Topic02]
---
[Back to the previous page](https://userdyk-github.github.io/pl03/PL03-Libraries.html) <br>
List of posts to read before reading this article
- <a href='https://userdyk-github.github.io/'>post1</a>
- <a href='https://userdyk-github.github.io/'>post2</a>
- <a href='https://userdyk-github.github.io/'>post3</a>

---

## Contents
{:.no_toc}

* ToC
{:toc}

<hr class="division1">

## **An Introduction to Deep Learning and Keras**

### ***A Sneak Peek into the Keras Framework***

```python
# Import required packages 
from keras.models import Sequential
from keras.layers import Dense
import numpy as np

# Getting the data ready 
# Generate train dummy data for 1000 Students and dummy test for 500
# Columns :Age, Hours of Study &Avg Previous test scores 
np.random.seed(2018)  #Setting seed for reproducibility 
train_data, test_data = np.random.random((1000, 3)), np.random.random((500, 3))

# Generate dummy results for 1000 students : Whether Passed (1) or Failed (0) 
labels = np.random.randint(2, size=(1000, 1))

# Defining the model structure with the required layers, 
# of neurons, activation function and optimizers
model = Sequential() 
model.add(Dense(5, input_dim=3, activation='relu'))
model.add(Dense(4, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# prediction
model.predict(test_data)
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
```
array([[0.46861026],
       [0.5       ],
       [0.5       ],
       [0.4871366 ],
       [0.49903315],
       [0.49717814],
       [0.5       ],
       [0.5       ],
       [0.48589122],
       [0.5       ],
       [0.45769817],
       [0.4761914 ],
       [0.457347  ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.4494737 ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.44512787],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.48044527],
       [0.47858024],
       [0.4603199 ],
       [0.45580456],
       [0.5       ],
       [0.4651043 ],
       [0.49338886],
       [0.4749441 ],
       [0.5       ],
       [0.49502167],
       [0.5       ],
       [0.47981036],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.48544034],
       [0.48941973],
       [0.5       ],
       [0.48072588],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.45014045],
       [0.44670266],
       [0.5       ],
       [0.5       ],
       [0.48535347],
       [0.5       ],
       [0.5       ],
       [0.47732565],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.49381864],
       [0.5       ],
       [0.46737075],
       [0.4895167 ],
       [0.5       ],
       [0.5       ],
       [0.48813877],
       [0.4902516 ],
       [0.5       ],
       [0.49239618],
       [0.48788795],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.46241233],
       [0.5       ],
       [0.5       ],
       [0.47910354],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.4778831 ],
       [0.5       ],
       [0.4809639 ],
       [0.49061456],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.4672264 ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.48984617],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.44785452],
       [0.44669122],
       [0.5       ],
       [0.45972908],
       [0.5       ],
       [0.4553304 ],
       [0.455316  ],
       [0.49323598],
       [0.4539035 ],
       [0.5       ],
       [0.47961783],
       [0.5       ],
       [0.5       ],
       [0.48219115],
       [0.5       ],
       [0.4614902 ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.45767388],
       [0.5       ],
       [0.46886587],
       [0.5       ],
       [0.5       ],
       [0.4554451 ],
       [0.49468303],
       [0.4883898 ],
       [0.4869569 ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.44213676],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.47811604],
       [0.5       ],
       [0.47985232],
       [0.5       ],
       [0.5       ],
       [0.4689154 ],
       [0.493751  ],
       [0.46989655],
       [0.47616476],
       [0.48950237],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.48598233],
       [0.4775344 ],
       [0.5       ],
       [0.45221633],
       [0.49905425],
       [0.5       ],
       [0.499446  ],
       [0.5       ],
       [0.46162453],
       [0.5       ],
       [0.47051904],
       [0.4691319 ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.4740395 ],
       [0.45277733],
       [0.5       ],
       [0.4564892 ],
       [0.5       ],
       [0.5       ],
       [0.49884546],
       [0.46130854],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.4926    ],
       [0.48179826],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.49798712],
       [0.5       ],
       [0.5       ],
       [0.45516366],
       [0.5       ],
       [0.5       ],
       [0.4920945 ],
       [0.5       ],
       [0.4598429 ],
       [0.5       ],
       [0.49746007],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.4860358 ],
       [0.49647668],
       [0.5       ],
       [0.49259648],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.43963608],
       [0.4893422 ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.48110956],
       [0.5       ],
       [0.5       ],
       [0.47620666],
       [0.48131967],
       [0.5       ],
       [0.44337678],
       [0.5       ],
       [0.47810593],
       [0.5       ],
       [0.49771672],
       [0.5       ],
       [0.4850363 ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.4728559 ],
       [0.5       ],
       [0.43829784],
       [0.5       ],
       [0.48699516],
       [0.47709987],
       [0.45873278],
       [0.5       ],
       [0.5       ],
       [0.46810988],
       [0.4423706 ],
       [0.45269522],
       [0.5       ],
       [0.5       ],
       [0.49126446],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.45363984],
       [0.5       ],
       [0.4955496 ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.4812972 ],
       [0.4961452 ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.49168992],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.4809775 ],
       [0.49608806],
       [0.5       ],
       [0.5       ],
       [0.47963938],
       [0.44129932],
       [0.5       ],
       [0.49104202],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.46731406],
       [0.5       ],
       [0.4763571 ],
       [0.48989794],
       [0.5       ],
       [0.47873837],
       [0.48685396],
       [0.44853798],
       [0.5       ],
       [0.45057768],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.44581726],
       [0.5       ],
       [0.470196  ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.48286352],
       [0.4708736 ],
       [0.5       ],
       [0.48428866],
       [0.49608368],
       [0.49180642],
       [0.49760553],
       [0.48642245],
       [0.5       ],
       [0.48359075],
       [0.5       ],
       [0.47129646],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.48513818],
       [0.5       ],
       [0.4847001 ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.45158532],
       [0.5       ],
       [0.43724394],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.49842736],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.486489  ],
       [0.5       ],
       [0.48554513],
       [0.46738636],
       [0.46067977],
       [0.5       ],
       [0.49288484],
       [0.49808577],
       [0.5       ],
       [0.47935903],
       [0.5       ],
       [0.5       ],
       [0.49170375],
       [0.5       ],
       [0.48575062],
       [0.47335696],
       [0.4707052 ],
       [0.49207035],
       [0.49726796],
       [0.47241187],
       [0.5       ],
       [0.48718768],
       [0.5       ],
       [0.5       ],
       [0.48753804],
       [0.4469036 ],
       [0.48337868],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.48221645],
       [0.5       ],
       [0.5       ],
       [0.44933993],
       [0.48225254],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.49955   ],
       [0.49696365],
       [0.5       ],
       [0.5       ],
       [0.4766759 ],
       [0.5       ],
       [0.5       ],
       [0.4987182 ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.48441914],
       [0.4998613 ],
       [0.49269322],
       [0.5       ],
       [0.5       ],
       [0.49953914],
       [0.45121452],
       [0.47463357],
       [0.5       ],
       [0.49355683],
       [0.49730018],
       [0.5       ],
       [0.45835817],
       [0.48800233],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.482607  ],
       [0.5       ],
       [0.5       ],
       [0.47719622],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.47293794],
       [0.45628643],
       [0.4928253 ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.49660018],
       [0.5       ],
       [0.5       ],
       [0.48088828],
       [0.4916831 ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.4545645 ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.48393992],
       [0.481249  ],
       [0.4806497 ],
       [0.5       ],
       [0.48546207],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.48384792],
       [0.43787992],
       [0.49809563],
       [0.44570938],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.47671646],
       [0.4882306 ],
       [0.48982742],
       [0.5       ],
       [0.49670562],
       [0.5       ],
       [0.49662828],
       [0.49385524],
       [0.5       ],
       [0.5       ],
       [0.45512325],
       [0.5       ],
       [0.48274958],
       [0.5       ],
       [0.5       ],
       [0.5       ],
       [0.49668145],
       [0.5       ]], dtype=float32)
```
<hr class='division3'>
</details>
<br><br><br>
<hr class="division2">

## **Keras in Action**

### ***Getting Started with DL in Keras***

```python

import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Activation
from keras.datasets import boston_housing

#Download the data using Keras; this will need an active internet connection
(x_train, y_train), (x_test, y_test) = boston_housing.load_data()


#Extract the last 100 rows from the training data to create the validation datasets. 
x_val = x_train[300:,]       # last 300 row
y_val = y_train[300:,]       # last 300 row

#Define the model architecture
model = Sequential()
model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))
model.add(Dense(6, kernel_initializer='normal', activation='relu'))
model.add(Dense(1, kernel_initializer='normal'))

# Compile model
model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_percentage_error'])

#Train the model
model.fit(x_train, y_train, batch_size=32, epochs=3, validation_data=(x_val,y_val))
```
<details markdown="1">
<summary class='jb-small' style="color:blue">TRAINING RESULT</summary>
<hr class='division3'>
```
Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz
57344/57026 [==============================] - 0s 2us/step

Train on 404 samples, validate on 104 samples
Epoch 1/3
404/404 [==============================] - 1s 2ms/step - loss: 580.9334 - mean_absolute_percentage_error: 99.4362 - val_loss: 662.7088 - val_mean_absolute_percentage_error: 98.0074
Epoch 2/3
404/404 [==============================] - 0s 51us/step - loss: 554.0448 - mean_absolute_percentage_error: 95.8691 - val_loss: 618.2133 - val_mean_absolute_percentage_error: 93.0662
Epoch 3/3
404/404 [==============================] - 0s 50us/step - loss: 492.5111 - mean_absolute_percentage_error: 87.4437 - val_loss: 520.5322 - val_mean_absolute_percentage_error: 81.4210
```
<hr class='division3'>
</details>
<details markdown="1">
<summary class='jb-small' style="color:blue">EVALUATION</summary>
<hr class='division3'>
```python
results = model.evaluate(x_test, y_test)
for i in range(len(model.metrics_names)):
    print(model.metrics_names[i]," : ", results[i])
```
`OUTPUT`
```
102/102 [==============================] - 0s 62us/step
loss  :  463.09825942095586
mean_absolute_percentage_error  :  78.82570214365043
```
<hr class='division3'>
</details>
<details markdown="1">
<summary class='jb-small' style="color:blue">RETRAINING(after tuning fitting parameters)</summary>
<hr class='division3'>
```python
#Train the model 
model.fit(x_train, y_train, batch_size=32, epochs=30, validation_data=(x_val,y_val))
```
`OUTPUT`
```
Train on 404 samples, validate on 104 samples
Epoch 1/30
404/404 [==============================] - 0s 58us/step - loss: 379.4086 - mean_absolute_percentage_error: 70.2558 - val_loss: 360.9293 - val_mean_absolute_percentage_error: 59.3759
Epoch 2/30
404/404 [==============================] - 0s 47us/step - loss: 228.6982 - mean_absolute_percentage_error: 48.1161 - val_loss: 198.9693 - val_mean_absolute_percentage_error: 40.2195
Epoch 3/30
404/404 [==============================] - 0s 49us/step - loss: 137.9041 - mean_absolute_percentage_error: 43.9592 - val_loss: 143.6277 - val_mean_absolute_percentage_error: 42.3353
Epoch 4/30
404/404 [==============================] - 0s 50us/step - loss: 128.0068 - mean_absolute_percentage_error: 48.4147 - val_loss: 136.8944 - val_mean_absolute_percentage_error: 40.8082
Epoch 5/30
404/404 [==============================] - 0s 55us/step - loss: 118.3841 - mean_absolute_percentage_error: 44.0519 - val_loss: 133.1419 - val_mean_absolute_percentage_error: 37.5794
Epoch 6/30
404/404 [==============================] - 0s 49us/step - loss: 111.5623 - mean_absolute_percentage_error: 40.6460 - val_loss: 128.8092 - val_mean_absolute_percentage_error: 35.8778
Epoch 7/30
404/404 [==============================] - 0s 50us/step - loss: 105.6107 - mean_absolute_percentage_error: 39.3712 - val_loss: 121.8723 - val_mean_absolute_percentage_error: 35.2191
Epoch 8/30
404/404 [==============================] - 0s 60us/step - loss: 100.5365 - mean_absolute_percentage_error: 38.5076 - val_loss: 116.7530 - val_mean_absolute_percentage_error: 34.0602
Epoch 9/30
404/404 [==============================] - 0s 55us/step - loss: 95.6473 - mean_absolute_percentage_error: 36.4750 - val_loss: 112.9952 - val_mean_absolute_percentage_error: 32.6358
Epoch 10/30
404/404 [==============================] - 0s 56us/step - loss: 91.3528 - mean_absolute_percentage_error: 35.8936 - val_loss: 107.6109 - val_mean_absolute_percentage_error: 32.4268
Epoch 11/30
404/404 [==============================] - 0s 62us/step - loss: 86.8670 - mean_absolute_percentage_error: 34.5687 - val_loss: 105.0734 - val_mean_absolute_percentage_error: 30.8377
Epoch 12/30
404/404 [==============================] - 0s 57us/step - loss: 83.8678 - mean_absolute_percentage_error: 33.1729 - val_loss: 100.9976 - val_mean_absolute_percentage_error: 30.1347
Epoch 13/30
404/404 [==============================] - 0s 79us/step - loss: 80.3338 - mean_absolute_percentage_error: 32.9414 - val_loss: 98.0269 - val_mean_absolute_percentage_error: 29.1839
Epoch 14/30
404/404 [==============================] - 0s 49us/step - loss: 77.0266 - mean_absolute_percentage_error: 31.3633 - val_loss: 96.0304 - val_mean_absolute_percentage_error: 28.0592
Epoch 15/30
404/404 [==============================] - 0s 69us/step - loss: 74.5713 - mean_absolute_percentage_error: 30.6367 - val_loss: 93.4559 - val_mean_absolute_percentage_error: 27.4387
Epoch 16/30
404/404 [==============================] - 0s 76us/step - loss: 72.4605 - mean_absolute_percentage_error: 30.5300 - val_loss: 90.2561 - val_mean_absolute_percentage_error: 27.5172
Epoch 17/30
404/404 [==============================] - 0s 56us/step - loss: 70.2668 - mean_absolute_percentage_error: 30.4674 - val_loss: 89.6360 - val_mean_absolute_percentage_error: 26.2286
Epoch 18/30
404/404 [==============================] - 0s 59us/step - loss: 69.0524 - mean_absolute_percentage_error: 28.2962 - val_loss: 89.3691 - val_mean_absolute_percentage_error: 25.0894
Epoch 19/30
404/404 [==============================] - 0s 59us/step - loss: 67.1439 - mean_absolute_percentage_error: 28.7645 - val_loss: 86.4003 - val_mean_absolute_percentage_error: 25.7927
Epoch 20/30
404/404 [==============================] - 0s 65us/step - loss: 66.1058 - mean_absolute_percentage_error: 29.1919 - val_loss: 85.8313 - val_mean_absolute_percentage_error: 25.0127
Epoch 21/30
404/404 [==============================] - 0s 55us/step - loss: 65.2683 - mean_absolute_percentage_error: 27.9101 - val_loss: 85.7227 - val_mean_absolute_percentage_error: 24.2154
Epoch 22/30
404/404 [==============================] - 0s 57us/step - loss: 64.3430 - mean_absolute_percentage_error: 28.2435 - val_loss: 84.4628 - val_mean_absolute_percentage_error: 24.4009
Epoch 23/30
404/404 [==============================] - 0s 56us/step - loss: 63.5753 - mean_absolute_percentage_error: 27.9445 - val_loss: 83.9498 - val_mean_absolute_percentage_error: 24.2201
Epoch 24/30
404/404 [==============================] - 0s 62us/step - loss: 62.9955 - mean_absolute_percentage_error: 28.0562 - val_loss: 83.1876 - val_mean_absolute_percentage_error: 24.3564
Epoch 25/30
404/404 [==============================] - 0s 52us/step - loss: 62.5542 - mean_absolute_percentage_error: 27.7791 - val_loss: 83.8650 - val_mean_absolute_percentage_error: 23.6271
Epoch 26/30
404/404 [==============================] - 0s 53us/step - loss: 62.1328 - mean_absolute_percentage_error: 27.1743 - val_loss: 82.4939 - val_mean_absolute_percentage_error: 24.0875
Epoch 27/30
404/404 [==============================] - 0s 58us/step - loss: 61.6133 - mean_absolute_percentage_error: 27.6719 - val_loss: 82.2328 - val_mean_absolute_percentage_error: 23.8878
Epoch 28/30
404/404 [==============================] - 0s 61us/step - loss: 60.8626 - mean_absolute_percentage_error: 26.9424 - val_loss: 82.7886 - val_mean_absolute_percentage_error: 23.2897
Epoch 29/30
404/404 [==============================] - 0s 54us/step - loss: 60.6314 - mean_absolute_percentage_error: 26.1994 - val_loss: 81.6793 - val_mean_absolute_percentage_error: 23.6167
Epoch 30/30
404/404 [==============================] - 0s 52us/step - loss: 60.5237 - mean_absolute_percentage_error: 27.4995 - val_loss: 81.5046 - val_mean_absolute_percentage_error: 23.4413
<keras.callbacks.History at 0x7fd199e50c18>
```
<hr class='division3'>
</details>
<details markdown="1">
<summary class='jb-small' style="color:blue">EVALUATION2</summary>
<hr class='division3'>
```python
results = model.evaluate(x_test, y_test)
for i in range(len(model.metrics_names)):
    print(model.metrics_names[i]," : ", results[i])
```
`OUTPUT`
```
102/102 [==============================] - 0s 92us/step
loss  :  65.75437209185432
mean_absolute_percentage_error  :  31.099634806315105
```
<hr class='division3'>
</details>
<br><br><br>

---

### ***Putting All the Building Blocks Together***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

<hr class="division2">

## **Deep Neural Networks for Supervised Learning: Regression**

### ***Exploring the Data***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

---

### ***Data Engineering***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

---

### ***Defining Model Baseline Performance***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

---

### ***Designing the DNN***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>


<hr class="division2">

## **Deep Neural Networks for Supervised Learning: Classification**

### ***Exploring the Data***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

---

### ***Data Engineering***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

---

### ***Defining Model Baseline Accuracy***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

---

### ***Designing the DNN for Classification***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

---

### ***Revisiting the Data***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

---

### ***DNNs for Classification with Improved Data***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>


<hr class="division2">

## **Tuning and Deploying Deep Neural Networks**

### ***What Is Regularization***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

---

### ***Hyperparameter Tuning***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

---


### ***Model Deployment***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>


<hr class="division2">

## **The Path Ahead**

### ***What’s Next for DL Expertise***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

<hr class="division1">

List of posts followed by this article
- [post1](https://userdyk-github.github.io/)
- <a href='https://userdyk-github.github.io/'>post2</a>
- <a href='https://userdyk-github.github.io/'>post3</a>

---

Reference
- Jojo Moolayil, Learn Keras for Deep Neural Networks, 2019
- <a href='https://userdyk-github.github.io/'>post2</a>
- <a href='https://userdyk-github.github.io/'>post3</a>

---





