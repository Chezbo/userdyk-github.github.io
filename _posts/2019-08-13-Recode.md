---
layout : post
title : Recode
categories: [RECODE]
comments : true
tags : [RECODE]
---

[Back to the previous page](https://userdyk-github.github.io/) ｜ <a href="https://github.com/userdyk-github/userdyk-github.github.io/blob/master/_posts/2019-08-13-Recode.md" target="_blank">page management</a>

## Contents
{:.no_toc}

* ToC
{:toc}

<hr class="division1">


｜<a href="" target="_blank">URL</a>
```python

```
<br><br><br>






#### 2020 - 0322

reshape｜<a href="https://www.youtube.com/watch?v=St7EhvnFi6c&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv&index=2" target="_blank">URL</a>
```python
import torch
import numpy as np

t = np.array([[[0,1,2],
               [3,4,5]],
               
              [[6,7,8],
               [9,10,11]]])

ft = torch.FloatTensor(t)
print(ft.shape)   # 2 2 3

print(ft.view([-1,3]))
print(ft.view([-1,3]).shape)   # 2 2 3
print()

print(ft.view([-1,2]))
print(ft.view([-1,2]).shape)
print()

print(ft.view([-1,1,3]))
print(ft.view([-1,1,3]).shape)
```
<br><br><br>



max, argmax｜<a href="https://www.youtube.com/watch?v=St7EhvnFi6c&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv&index=2" target="_blank">URL</a>
```python
import torch

t = torch.FloatTensor([[1,2],
                       [3,4]])

print(t)
print(t.max())
print()

print(t.max(dim=0))      # max
print(t.max(dim=0)[0])   # argmax
print(t.max(dim=0)[1])   # argmax
print()

print(t.max(dim=1))
print(t.max(dim=-1))
```
<br><br><br>




sum｜<a href="https://www.youtube.com/watch?v=St7EhvnFi6c&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv&index=2" target="_blank">URL</a>
```python
import torch

t = torch.FloatTensor([[1,2],
                       [3,4]])
print(t)
print(t.sum())
print(t.sum(dim=0))
print(t.sum(dim=1))
print(t.sum(dim=-1))
```
<br><br><br>



multiplication｜<a href="https://www.youtube.com/watch?v=St7EhvnFi6c&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv&index=2" target="_blank">URL</a>
```python
import torch

t = torch.FloatTensor([1,2])
print(t)
print(t.mean())
print()


# Can't use .mean() for Integers
t = torch.LongTensor([1,2])
try:
    print(t.mean())
except Exception as exc:
    print(exc)
print()


# for higher rank tensors
t = torch.FloatTensor([[1,2],
                       [3,4]])
print(t)
print(t.mean())
print(t.mean(dim=0))
print(t.mean(dim=1))
print(t.mean(dim=-1))
```
<br><br><br>


broadcasting(2)｜<a href="https://www.youtube.com/watch?v=St7EhvnFi6c&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv&index=2" target="_blank">URL</a>
```python
import torch

m1 = torch.FloatTensor([[1,2],[3,4]])
m2 = torch.FloatTensor([[1],[2]])
print("m1 : ",m1.shape)   # 2*2
print("m2 : ",m2.shape)   # 2*1


print(m1.matmul(m2))      # 2*1
print(m1@m2)              # 2*1
print(m1 * m2)         # 2*2
print(m1.mul(m2))      # 2*2
```
<br><br><br>



broadcasting(1)｜<a href="https://www.youtube.com/watch?v=St7EhvnFi6c&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv&index=2" target="_blank">URL</a>
```python
import torch

# same shape
m1 = torch.FloatTensor([[3,3]])
m2 = torch.FloatTensor([[2,2]])
print(m1+m2)

# matrix + matrix
m1 = torch.FloatTensor([[1,2]])
m2 = torch.FloatTensor([[3]])
print(m1 + m2)

# matrix + vector
m1 = torch.FloatTensor([[1,2]])
m2 = torch.FloatTensor([3])
print(m1 + m2)

# 2*1 + 1*2 matrix
m1 = torch.FloatTensor([[1,2]])
m2 = torch.FloatTensor([[3],[10]])
print(m1 + m2)
```
<br><br><br>


tensor operation｜<a href="https://www.youtube.com/watch?v=St7EhvnFi6c&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv&index=2" target="_blank">URL</a>
```python
import torch


t = torch.FloatTensor([0,1,2,3,4,5,6])
print(t)
print(t.dim())
print(t.shape)
print(t.size())
print(t[0],t[-1])
print(t[2:3])
print(t[4:-1])
print(t[2:],t[:5])
print()


t = torch.FloatTensor([[1,2,3],
                       [4,5,6],
                       [7,8,9],
                       [10,11,12]])
print(t)
print(t.dim())
print(t.size())
print(t[:,1])
print(t[:,1].size())
print(t[:,:-1])
```
<br><br><br>



#### 2020 - 0321

mnist example｜<a href="http://www.gisdeveloper.co.kr/?paged=19&cat=132" target="_blank">URL</a>
```python
import torch
import torchvision
import matplotlib.pyplot as plt
import numpy as np

# data
batch_size = 1000
mnist_train = torchvision.datasets.MNIST(root="MNIST_data/", train=True, transform=torchvision.transforms.ToTensor(), download=True)
mnist_test = torchvision.datasets.MNIST(root="MNIST_data/", train=False, transform=torchvision.transforms.ToTensor(), download=True)
data_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)

# model
device = torch.device("cuda:0")
linear = torch.nn.Linear(784, 10, bias=True).to(device)
loss = torch.nn.CrossEntropyLoss().to(device)
SGD = torch.optim.SGD(linear.parameters(), lr=0.1)

# hyper-parameters
total_batch = len(data_loader)
training_epochs = 5


# training
for epoch in range(training_epochs):
    total_cost = 0

    AVG_COST = []
    for X, Y in data_loader:
        X = X.view(-1, 28*28).to(device)
        Y = Y.to(device)

        hypothesis = linear(X)
        cost = loss(hypothesis, Y)

        SGD.zero_grad()
        cost.backward()
        SGD.step()

        total_cost += cost

    avg_cost = total_cost / total_batch
    AVG_COST.append(avg_cost.detach().cpu().clone().numpy())   # https://discuss.pytorch.org/t/cant-convert-cuda-tensor-to-numpy-use-tensor-cpu-to-copy-the-tensor-to-host-memory-first/38301
    print("Epoch", "%03d"%(epoch+1), "cost =", "{:.9f}".format(avg_cost))

print(AVG_COST)
plt.plot(AVG_COST)
plt.savefig('result.png')
```
reference

- [https://bob3rdnewbie.tistory.com/category/Machine%20Learning/PyTorch](https://bob3rdnewbie.tistory.com/category/Machine%20Learning/PyTorch)

<br><br><br>




activation｜<a href="http://www.gisdeveloper.co.kr/?paged=20&cat=132" target="_blank">URL</a>
```python
import numpy as np
import matplotlib.pyplot as plt

def sigmoid(x):
    return 1/(1+np.exp(-x))

def step(x):
    return np.array(x>0, dtype=int)

def relu(x):
    return np.maximum(x,0)

def softmax(x):
    return np.exp(x-np.max(x))/np.sum(np.exp(x-np.max(x)))

def tanh(x):
    return np.tanh(x)



x_range = np.arange(-10,1000, 0.1)

plt.plot(x_range, sigmoid(x_range), label='sigmoid')
plt.plot(x_range, step(x_range), label='step')
plt.plot(x_range, relu(x_range), label='relu')
plt.plot(x_range, softmax(x_range), label='softmax')
plt.plot(x_range, tanh(x_range), label='tanh')
plt.legend()
plt.savefig('result.png')
```
<br><br><br>


